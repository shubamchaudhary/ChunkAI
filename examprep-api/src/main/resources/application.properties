# Server Configuration
server.port=8080
spring.application.name=examprep-ai

# Increase response size limits for large context windows and file uploads
server.tomcat.max-http-form-post-size=1GB
spring.codec.max-in-memory-size=1GB

# Database Configuration
spring.datasource.url=jdbc:postgresql://127.0.0.1:5434/examprep_db?user=examprep&password=examprep123
spring.datasource.username=examprep
spring.datasource.password=examprep123
spring.datasource.driver-class-name=org.postgresql.Driver

# HikariCP Connection Pool Configuration (for parallel processing)
spring.datasource.hikari.minimum-idle=10
spring.datasource.hikari.maximum-pool-size=20
spring.datasource.hikari.connection-timeout=60000
spring.datasource.hikari.idle-timeout=300000
spring.datasource.hikari.max-lifetime=600000
spring.datasource.hikari.leak-detection-threshold=60000

# JPA Configuration
spring.jpa.hibernate.ddl-auto=validate
spring.jpa.show-sql=false
spring.jpa.properties.hibernate.dialect=org.hibernate.dialect.PostgreSQLDialect
spring.jpa.properties.hibernate.format_sql=true

# Gemini API Configuration
gemini.api-key=AIzaSyAT4Q5iOqmp3_yFe-V-lOoQa4KlReSgI2I
gemini.embedding-model=text-embedding-004
gemini.generation-model=gemini-2.5-flash
gemini.base-url=https://generativelanguage.googleapis.com/v1beta
gemini.max-retries=3
gemini.timeout-seconds=60
gemini.max-output-tokens=8192
gemini.max-context-chunks=100
gemini.max-conversation-history=50

# API Key Rate Limiting Configuration (for embeddings only - content generation uses router)
# Set to 8 (80% of 10 RPM) for Gemini embeddings
# Content generation uses multi-provider router with 80 RPM total capacity
gemini.requests-per-minute=8
gemini.requests-per-day=1500

# Multi-Provider LLM Router Configuration
# Weighted round-robin routing across multiple free-tier LLM providers
# Total combined: 80 RPM (80% of 100 RPM capacity) for content generation
# Using 80% of each provider's capacity for safety margin
llm.router.max-retries=5
llm.router.cooldown-ms=120000
llm.router.retry-delay-ms=2000

# Provider API Keys (can also be set via environment variables)
# Using 80% of each provider's capacity:
# GROQ - 30 RPM -> 24 RPM (80%)
llm.groq.api-key=${LLM_GROQ_API_KEY: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}
llm.groq.rpm=24

# CEREBRAS - 30 RPM -> 24 RPM (80%)
llm.cerebras.api-key=${LLM_CEREBRAS_API_KEY:csk-d8m49whmj3p35t354c8y3688nxcnfchre4tppvhcdkrmywmy}
llm.cerebras.rpm=24

# COHERE - 20 RPM -> 16 RPM (80%)
llm.cohere.api-key=${LLM_COHERE_API_KEY:nAmFRlOcHlTP8LlLx4Id3FcVo6Gabgxhmh72HwGD}
llm.cohere.rpm=16

# GEMINI - 10 RPM -> 8 RPM (80%) (also uses existing gemini.api-key if LLM_GEMINI_API_KEY not set)
llm.gemini.api-key=${LLM_GEMINI_API_KEY:${gemini.api-key:}}
llm.gemini.rpm=8

# SAMBANOVA - 10 RPM -> 8 RPM (80%)
llm.sambanova.api-key=${LLM_SAMBANOVA_API_KEY:ca92a83c-01e0-4e9c-9977-13de4b8956ea}
llm.sambanova.rpm=8

# Document Processing Configuration
# Enable/disable document-level metadata generation (summary, topics, entities)
# Keep enabled to maintain v2.0 architecture features
document.processing.enable-metadata-generation=true

# JWT Configuration
jwt.secret=${JWT_SECRET:your-secret-key-change-in-production-min-256-bits-please-use-a-long-random-string}
jwt.expiration=86400000

# Development Mode - Allow unauthenticated access (SET TO FALSE IN PRODUCTION!)
# This allows the frontend to work without authentication during development
# WARNING: This should NEVER be enabled in production environments
security.dev-mode.enabled=true

# File Upload Configuration - ChatGPT/Claude-like capacity
spring.servlet.multipart.enabled=true
spring.servlet.multipart.max-file-size=1GB
spring.servlet.multipart.max-request-size=2GB
spring.servlet.multipart.file-size-threshold=2MB

# File Storage Configuration
file.storage.directory=./uploads

# Logging
logging.level.com.examprep=INFO
logging.level.org.springframework.security=DEBUG

# Gemini Embedding Configuration (Batch API)
gemini.embedding.api-key=${GEMINI_EMBEDDING_API_KEY:${gemini.api-key}}
gemini.embedding.model=text-embedding-004
gemini.embedding.batch-size=100
gemini.embedding.rate-limit-rpm=100
gemini.embedding.retry-attempts=3
gemini.embedding.retry-delay-ms=1000
gemini.base-url=https://generativelanguage.googleapis.com/v1beta

# Batch Embedding Processing Configuration
batch.embedding.enabled=true
batch.embedding.job-interval-ms=5000
batch.embedding.max-chunks-per-run=500

# Document Processing - Metadata Generation Disabled
document.processing.enable-metadata-generation=false

# Embedding Service Configuration
embedding.use-batch-api=true

